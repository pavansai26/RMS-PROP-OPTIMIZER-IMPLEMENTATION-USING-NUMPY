{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RMS PROP OPTIMIZER IMPLEMENTATION.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP/TWVAKJW68RcRiJ5RV5Jd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/RMS-PROP-OPTIMIZER-IMPLEMENTATION-USING-NUMPY/blob/master/RMS_PROP_OPTIMIZER_IMPLEMENTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMxNRslYSMR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-omubAC-Zk8D",
        "colab_type": "text"
      },
      "source": [
        "RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-4RBOJUZqNf",
        "colab_type": "text"
      },
      "source": [
        "$$\\mathbf{w}_{t+1} = \\mathbf{w}_{t} - \\frac{\\eta}{\\sqrt{\\mathbb{E}[g^{2}]_{t} + \\epsilon}} \\odot g_{t}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf0MyePHZy_t",
        "colab_type": "text"
      },
      "source": [
        "where moving average $\\mathbb{E}[g^{2}]_{t}$ is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojRcC2x0Z4Le",
        "colab_type": "text"
      },
      "source": [
        "$$\\mathbb{E}[g^{2}]_{t} = \\gamma \\mathbb{E}[g^{2}]_{t-1} + (1 - \\gamma) g_{t}^{2},$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGojx6H0aELp",
        "colab_type": "text"
      },
      "source": [
        "and $\\gamma$ is 0.9 usually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHl9UW4aJuZ",
        "colab_type": "text"
      },
      "source": [
        "importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHGI8UkGZmPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.colors import LogNorm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3H1_1q5R5u",
        "colab_type": "text"
      },
      "source": [
        "Beale function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvlLmMIy5X92",
        "colab_type": "text"
      },
      "source": [
        "$$ f(x, y) = (1.5 - x + xy)^{2} + (2.25 - x + xy^{2})^{2} + (2.625 - x +xy^{3})^{2}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8MKUTO-5jPb",
        "colab_type": "text"
      },
      "source": [
        "analytic solution (global minima)\n",
        "$(x, y) = (3, 0.5)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lAr40N-5r4f",
        "colab_type": "text"
      },
      "source": [
        "implementaion of beale function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QmxLcDZ5qiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdtYQlPq85fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradients(x, y):\n",
        "  \"\"\"Gradient of Beale function.\n",
        "\n",
        "  Args:\n",
        "    x: x-dimension of inputs\n",
        "    y: y-dimension of inputs\n",
        "\n",
        "  Returns:\n",
        "    grads: [dx, dy], shape: 1-rank Tensor (vector) np.array\n",
        "      dx: gradient of Beale function with respect to x-dimension of inputs\n",
        "      dy: gradient of Beale function with respect to y-dimension of inputs\n",
        "  \"\"\"\n",
        "  dx = 2. * ( (1.5 - x + x * y) * (y - 1) + \\\n",
        "                (2.25 - x + x * y**2) * (y**2 - 1) + \\\n",
        "                (2.625 - x + x * y**3) * (y**3 - 1) )\n",
        "  dy = 2. * ( (1.5 - x + x * y) * x + \\\n",
        "              (2.25 - x + x * y**2) * 2. * x * y + \\\n",
        "              (2.625 - x + x * y**3) * 3. * x * y**2 )\n",
        "  grads = np.array([dx, dy])\n",
        "  return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jw4v47SbYDn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Build a Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93fhTZJ6aS8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RMSPropOptimizer():\n",
        "  def __init__(self, x_init=None, y_init=None,learning_rate=0.001, decay=0.9, epsilon=1e-10):\n",
        "    scale = 3.0\n",
        "    self.g = gradients\n",
        "    self.vars = np.zeros([2])\n",
        "\n",
        "    if x_init is not None:\n",
        "      self.vars[0] = x_init\n",
        "    else:\n",
        "      self.vars[0] = np.random.uniform(low=-scale, high=scale)\n",
        "    \n",
        "    if y_init is not None:\n",
        "      self.vars[1] = y_init\n",
        "    else:\n",
        "      self.vars[1] = np.random.uniform(low=-scale, high=scale)\n",
        "    \n",
        "    print(\"x_init: {:.3f}\".format(self.vars[0]))\n",
        "    print(\"y_init: {:.3f}\".format(self.vars[1]))\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.grads_squared = np.zeros([2])\n",
        "    self.decay = decay\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "    # for accumulation of loss and path (w, b)\n",
        "    self.z_history = []\n",
        "    self.x_history = []\n",
        "    self.y_history = []\n",
        "\n",
        "  def gradients(self, variables):\n",
        "    \"\"\"Gradient of Beale function.\n",
        "    \n",
        "    Args:\n",
        "      variables: input data, shape: 1-rank Tensor (vector) np.array\n",
        "        x: x-dimension of inputs\n",
        "        y: y-dimension of inputs\n",
        "      \n",
        "    Returns:\n",
        "      grads: [dx, dy], shape: 1-rank Tensor (vector) np.array\n",
        "        dx: gradient of Beale function with respect to x-dimension of inputs\n",
        "        dy: gradient of Beale function with respect to y-dimension of inputs\n",
        "    \"\"\"\n",
        "    x, y = variables\n",
        "    grads = self.g(x, y)\n",
        "    return grads\n",
        "\n",
        "  def weights_update(self, grads):\n",
        "    \"\"\"Weights update using RMSprop.\n",
        "     grads2 = decay * grads2 + (1 - decay) * grad2**2\n",
        "      w' = w - lr * graps / (sqrt(grad2) + epsilon)\n",
        "    \"\"\"\n",
        "    self.grads_squared = self.decay * self.grads_squared + (1. - self.decay) * grads**2\n",
        "    self.vars = self.vars - self.lr * grads / (np.sqrt(self.grads_squared) + self.epsilon)\n",
        "\n",
        "    def train(self, max_steps):\n",
        "      pre_z = 0.0\n",
        "      print(\"steps: {}  z: {:.6f}  x: {:.5f}  y: {:.5f}\".format(0, self.func(self.vars), self.x, self.y))\n",
        "    \n",
        "      file = open('rmsprop.txt', 'w')\n",
        "      file.write(\"{:.5f}  {:.5f}\\n\".format(self.x, self.y))\n",
        "\n",
        "      for step in range(max_steps):\n",
        "        self.z = self.func(self.vars)\n",
        "        self.history_update(self.z, self.x, self.y)\n",
        "\n",
        "        self.grads = self.gradients(self.vars)\n",
        "        self.weights_update(self.grads)\n",
        "        file.write(\"{:.5f}  {:.5f}\\n\".format(self.x, self.y))\n",
        "\n",
        "        if (step+1) % 100 == 0:\n",
        "          print(\"steps: {}  z: {:.6f}  x: {:.5f}  y: {:.5f}  dx: {:.5f}  dy: {:.5f}\".format(step+1, self.func(self.vars), self.x, self.y, self.dx, self.dy))\n",
        "        \n",
        "        if np.abs(pre_z - self.z) < 1e-7:\n",
        "          print(\"Enough convergence\")\n",
        "          print(\"steps: {}  z: {:.6f}  x: {:.5f}  y: {:.5f}\".format(step+1, self.func(self.vars), self.x, self.y))\n",
        "          self.z = self.func(self.vars)\n",
        "          self.history_update(self.z, self.x, self.y)\n",
        "          break\n",
        "        pre_z = self.z\n",
        "      file.close()\n",
        "      \n",
        "    self.x_history = np.array(self.x_history)\n",
        "    self.y_history = np.array(self.y_history)\n",
        "    self.path = np.concatenate((np.expand_dims(self.x_history, 1), np.expand_dims(self.y_history, 1)), axis=1).T\n",
        "    \n",
        "  @property\n",
        "  def x(self):\n",
        "    return self.vars[0]\n",
        "  \n",
        "  @property\n",
        "  def y(self):\n",
        "    return self.vars[1]\n",
        "  \n",
        "  @property\n",
        "  def dx(self):\n",
        "    return self.grads[0]\n",
        "  \n",
        "  @property\n",
        "  def dy(self):\n",
        "    return self.grads[1]\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwpeBLgECfeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}